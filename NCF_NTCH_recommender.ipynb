{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ehlBSjrw2PUt"},"outputs":[],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B8yBIIwvvwxx"},"outputs":[],"source":["!pip uninstall tensorflow -y\n","!pip install -q tensorflow==2.11.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CZsYrxZZvkPq"},"outputs":[],"source":["# https://huggingface.co/sentence-transformers/distiluse-base-multilingual-cased-v2\n","!pip install -U -q sentence-transformers"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"s8kJ9G4-2B2V","executionInfo":{"status":"ok","timestamp":1691381940161,"user_tz":-480,"elapsed":5561,"user":{"displayName":"Ching-jung Lin","userId":"01061587562790755372"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import re\n","import random\n","\n","import tensorflow as tf\n","from tensorflow.keras import models, Model, layers, regularizers\n","\n","import time\n","from datetime import datetime\n","from dateutil.relativedelta import relativedelta\n","import math\n","import gc"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Xqtji44yVMao","executionInfo":{"status":"ok","timestamp":1691381940162,"user_tz":-480,"elapsed":33,"user":{"displayName":"Ching-jung Lin","userId":"01061587562790755372"}}},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"OQhB0hROslBk"},"source":["#讀入資料"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"PsiiTrAm2WQj","executionInfo":{"status":"ok","timestamp":1691381940162,"user_tz":-480,"elapsed":31,"user":{"displayName":"Ching-jung Lin","userId":"01061587562790755372"}}},"outputs":[],"source":["def read_raw_data():\n","  raw_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/extract_data_221123.csv')\n","\n","  # 把日期相關欄位轉為日期格式 yyyy-mm-dd hh:mm:ss\n","  raw_data['order_time'] = pd.DatetimeIndex(raw_data['訂單日期'])\n","  raw_data['first_order'] = pd.DatetimeIndex(raw_data['first_order'])\n","  raw_data['concert_time'] = pd.DatetimeIndex(raw_data['concert_time'])\n","\n","  # 衍生欄位\n","  raw_data['dow'] = raw_data['concert_time'].dt.day_name()\n","\n","  # 使用者下訂時間距音樂會時間分組\n","  # 當天: 0；1~7天: 1；8~14天: 2；15~30天: 3；31~60天: 4；60天以上: 5；沒買: 6\n","  raw_data['order_concert'] = raw_data['concert_time'] - raw_data['order_time']\n","  raw_data['order_concert'] = raw_data['order_concert'].dt.days\n","  raw_data['order_concert_group'] = raw_data['order_concert'].apply(lambda x : 0 if x == 0 else\n","                                                                    1 if x <= 7 else\n","                                                                    2 if x <= 14 else\n","                                                                    3 if x <= 30 else\n","                                                                    4 if x <= 60 else 5)\n","\n","  raw_data = raw_data.rename(columns = {'訂購人會員代碼' : 'userID',\n","                                        '場次代碼' : 'itemID'})\n","\n","\n","\n","  ## ===== user data  ==== ##\n","  # 有 81位使用者沒有資料\n","  # 最後模型沒有用到 age & gender\n","  user_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/raw_member_data_210827.csv')\n","  user_data['bd'] = pd.DatetimeIndex(user_data['生日'])\n","\n","  raw_data = raw_data.merge(user_data, left_on = 'userID', right_on = '會員代碼')\n","\n","  #raw_data['age'] = raw_data['order_time'].dt.year-raw_data['bd'].dt.year\n","  #raw_data['gender'] = raw_data['性別'].apply(lambda x : 'F' if x=='女' else 'M')\n","\n","  # 18以下；19-29；30-65；65+\n","  #raw_data['age_group'] = pd.cut(raw_data['age'],\n","  #                              bins = [0, 18, 30, 65, 200], labels = [0, 1, 2, 3],\n","  #                              include_lowest = True)\n","\n","  ## ===== category  ==== ##\n","  # 音樂會類別：國內外、類別\n","  # 獨奏、獨唱、獨唱獨奏合併為一列\n","  # 大陸音樂團體、打擊樂、歌劇、爵士樂、管絃樂併入其他音樂節目\n","  cat = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/category.csv')\n","\n","  cat['category'] = cat['category'].replace('獨奏', '獨唱獨奏')\n","  cat['category'] = cat['category'].replace('獨唱', '獨唱獨奏')\n","  cat['category'] = cat['category'].replace('大陸音樂團體', '其他音樂節目')\n","  cat['category'] = cat['category'].replace('打擊樂', '其他音樂節目')\n","  cat['category'] = cat['category'].replace('歌劇', '其他音樂節目')\n","  cat['category'] = cat['category'].replace('爵士樂', '其他音樂節目')\n","  cat['category'] = cat['category'].replace('管絃樂', '其他音樂節目')\n","\n","  cat = cat.rename(columns = {'場次代碼' : 'itemID'})\n","\n","  raw_data = raw_data.merge(cat, on = 'itemID')\n","\n","  # 目標變數欄\n","  raw_data['y'] = 1\n","\n","  # 為節省記憶體空間，另存新檔\n","  file_name = 'raw_data.csv'\n","  raw_data.to_csv(file_name, index = False, encoding='utf8')\n","\n","  return file_name"]},{"cell_type":"markdown","metadata":{"id":"H4C_JPP1CzqX"},"source":["## dictionaries"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"uM-Oy7W9C03O","executionInfo":{"status":"ok","timestamp":1691381989337,"user_tz":-480,"elapsed":2,"user":{"displayName":"Ching-jung Lin","userId":"01061587562790755372"}}},"outputs":[],"source":["# 各類別變數字典\n","def dic_generate(raw_data_file_name):\n","  raw_data = pd.read_csv(raw_data_file_name)\n","  raw_data['bd'] = pd.DatetimeIndex(raw_data['bd'])\n","  raw_data['concert_time'] = pd.DatetimeIndex(raw_data['concert_time'])\n","\n","  dow_dict = raw_data[['itemID', 'dow']].drop_duplicates().set_index('itemID').T.to_dict('list')\n","  inter_dict = raw_data[['itemID', 'inter']].drop_duplicates().set_index('itemID').T.to_dict('list')\n","  cat_dict = raw_data[['itemID', 'category']].drop_duplicates().set_index('itemID').T.to_dict('list')\n","  concert_time_dict = raw_data[['itemID', 'concert_time']].drop_duplicates().set_index('itemID').T.to_dict()\n","\n","  return dow_dict, inter_dict, cat_dict, concert_time_dict\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"d_7mJZWnB8Gq","executionInfo":{"status":"ok","timestamp":1691382019164,"user_tz":-480,"elapsed":6432,"user":{"displayName":"Ching-jung Lin","userId":"01061587562790755372"}}},"outputs":[],"source":["# 產生raw_data\n","raw_data_file_name = read_raw_data()\n","# 產生類別字典\n","dow_dict, inter_dict, cat_dict, concert_time_dict = dic_generate(raw_data_file_name)"]},{"cell_type":"markdown","metadata":{"id":"jaxl-9OAvfeD"},"source":["## title embedding"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"B1HMcyouoeac","executionInfo":{"status":"ok","timestamp":1691382032721,"user_tz":-480,"elapsed":7280,"user":{"displayName":"Ching-jung Lin","userId":"01061587562790755372"}}},"outputs":[],"source":["# https://huggingface.co/sentence-transformers/distiluse-base-multilingual-cased-v2\n","\n","from sentence_transformers import SentenceTransformer\n","\n","def title_embedding(raw_data_file_name):\n","  raw_data = pd.read_csv(raw_data_file_name)\n","  raw_data['title'] = raw_data['產品名稱']\n","\n","  title_model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v2')\n","\n","  title = raw_data[['title', 'itemID']].drop_duplicates().reset_index(drop = True)\n","  title_enc = title_model.encode(title['title'])\n","\n","  # 建立 title_idx 作為之後對應時的 index\n","  title['title_idx'] = [x for x in range(len(title))]\n","  title_enc_dict = title[['itemID', 'title_idx']].set_index('itemID').T.to_dict('list')\n","\n","  return title_enc, title, title_enc_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bIjZfB3RvoB3"},"outputs":[],"source":["# 產生 title_idx\n","title_enc, title, title_enc_dict = title_embedding(raw_data_file_name)"]},{"cell_type":"markdown","metadata":{"id":"XSoGFJWbshIM"},"source":["#train set"]},{"cell_type":"markdown","metadata":{"id":"wAher3rK6Eia"},"source":["## expand\n","\n","製作「未購買」紀錄：\n","\n","挑選訓練時間前18個月內下架的節目，為訓練集內的使用者製作「未購買」的資料。每位使用者的「未購買」資料筆數設為訓練集長度的1/500。"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"AavrmI6Pwehn","executionInfo":{"status":"ok","timestamp":1691382056270,"user_tz":-480,"elapsed":8,"user":{"displayName":"Ching-jung Lin","userId":"01061587562790755372"}}},"outputs":[],"source":["def train_filter(train_set):\n","  while True:\n","    item_group = train_set.groupby('itemID').size().to_frame('item_count').reset_index()\n","    item_group = item_group[item_group['item_count'] > 1]\n","    train_set = train_set[train_set['itemID'].isin(list(item_group['itemID']))]\n","\n","    user_group = train_set.groupby('userID').size().to_frame('user_count').reset_index()\n","    user_group = user_group[user_group['user_count'] > 1]\n","    train_set = train_set[train_set['userID'].isin(list(user_group['userID']))]\n","\n","    if min(item_group['item_count']) > 1 and min(user_group['user_count']) > 1:\n","      return train_set"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"5v6kYCi7r4G7","executionInfo":{"status":"ok","timestamp":1691382056270,"user_tz":-480,"elapsed":8,"user":{"displayName":"Ching-jung Lin","userId":"01061587562790755372"}}},"outputs":[],"source":["t = datetime(2019, 1, 1)\n","\n","def train_expand(d):\n","  raw_data = pd.read_csv(raw_data_file_name)\n","  #把日期相關欄位轉為日期格式 yyyy-mm-dd hh:mm:ss\n","  raw_data['order_time'] = pd.DatetimeIndex(raw_data['訂單日期'])\n","  raw_data['first_order'] = pd.DatetimeIndex(raw_data['first_order'])\n","  raw_data['concert_time'] = pd.DatetimeIndex(raw_data['concert_time'])\n","\n","  train_time = t + relativedelta(days = d*15)\n","  train_set = raw_data[raw_data['order_time'] < train_time]\n","\n","  # 只保留有一筆以上的資料\n","  # 大約會少掉 20,000筆\n","  train_set = train_filter(train_set)\n","\n","  # 使用者最近一次下單 (recent)\n","  recent = train_set[['userID', 'order_time']].sort_values(by = 'order_time', ascending = False).drop_duplicates(subset='userID')\n","  recent['order_time'] = (train_time - recent['order_time']).dt.days\n","\n","  # 最近一次下單時間分組\n","  # 0: 0~7 / 1: 8~14 / 2: 15~21 / 3: 22~31/ 4: 31~60 / 5: 61~90 / 6: 91~180 / 7: 181~365 / 8: 366~730 / 9: 731~1095 / 10: 1096+\n","  recent['recent_group'] = recent['order_time'].apply(lambda x : 0 if x <=7 else\n","                                                      (1 if x <= 14 else\n","                                                      2 if x <= 21 else\n","                                                      3 if x <= 31 else\n","                                                      4 if x <= 60 else\n","                                                      5 if x <= 90 else\n","                                                      6 if x <= 180 else\n","                                                      7 if x <= 365 else\n","                                                      8 if x <= 730 else\n","                                                      9 if x <= 1095 else\n","                                                      10))\n","  recent_group_dict = recent[['userID', 'recent_group']].set_index('userID').T.to_dict('list')\n","\n","  # 使用者下訂時間距音樂會時間分組\n","  # 當天: 0；1~7天: 1；8~14天: 2；15~30天: 3；31~60天: 4；60天以上: 5；沒買: 6（為「未購買」紀錄）\n","  train_set['order_concert'] = train_set['concert_time'] - train_set['order_time']\n","  train_set['order_concert'] = train_set['order_concert'].dt.days\n","  train_set['order_concert_group'] = train_set['order_concert'].apply(lambda x : 0 if x == 0 else\n","                                                                      1 if x <= 7 else\n","                                                                      2 if x <= 14 else\n","                                                                      3 if x <= 30 else\n","                                                                      4 if x <= 60 else 5)\n","\n","  train_set = train_set.drop_duplicates(subset = ['userID', 'itemID'])\n","\n","  # 訓練集中 train_time 後尚在架上的節目\n","  avail_event = train_set[(train_set['concert_time'] > train_time) & (train_set['first_order'] <= train_time)]['itemID'].unique()\n","\n","  # 每個使用者產生未購買的資料\n","  # 從近18個月內下架的節目中挑\n","  train_expand_time = train_time - relativedelta(months = 18)\n","\n","  expand_users = train_set['userID'].unique()\n","  expand_items = list(train_set[(train_set['concert_time'] < train_time) & (train_set['concert_time'] >= train_expand_time)]['itemID'].unique())\n","\n","  sample_size = int(len(train_set)/500)\n","  total_expand = []\n","\n","  for u in expand_users:\n","    # 組合使用者和所有產品的 tuple\n","    expand_pairs = set((u, i) for i in expand_items)\n","\n","    # 移除使用者買過的產品\n","    user_sub = train_set[train_set['userID'] == u]\n","    train_pairs = set(zip(user_sub['userID'], user_sub['itemID']))\n","    expand_pairs = expand_pairs - train_pairs\n","\n","    # 抽樣\n","    # 如果可選產品小於 sample_size 則全部保留\n","    if len(expand_pairs) > sample_size:\n","      expand_pairs = random.sample(expand_pairs, sample_size)\n","\n","    total_expand = total_expand + expand_pairs\n","\n","  # 組合 expand 資料\n","  expand_train = pd.DataFrame(total_expand, columns = ['userID', 'itemID'])\n","  expand_train['dow'] = expand_train['itemID'].apply(lambda x: dow_dict[x][0])\n","  expand_train['inter'] = expand_train['itemID'].apply(lambda x: inter_dict[x][0])\n","  expand_train['category'] = expand_train['itemID'].apply(lambda x: cat_dict[x][0])\n","  expand_train['order_concert_group'] = 6\n","  expand_train['y'] = 0\n","\n","  # 合併資料\n","  train_set = pd.concat([train_set, expand_train])\n","\n","  # 為所有資料補上使用者最近購買分組\n","  train_set['recent_group'] = train_set['userID'].apply(lambda x : recent_group_dict[x][0])\n","\n","  # 只保留必要欄位\n","  train_set = train_set[['userID', 'itemID', 'dow', 'inter',\n","                         'category', 'recent_group', 'order_concert_group',\n","                         'y']]\n","\n","  train_set = train_set.sample(frac = 1).reset_index(drop = True)\n","\n","  train_path = 'train.csv'\n","  train_set.to_csv(train_path, index = False)\n","\n","  return train_time, train_path, avail_event, recent_group_dict"]},{"cell_type":"markdown","metadata":{"id":"f56FK5kprog1"},"source":["##編流水號"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"G6sV4i242ia0","executionInfo":{"status":"ok","timestamp":1691382056271,"user_tz":-480,"elapsed":8,"user":{"displayName":"Ching-jung Lin","userId":"01061587562790755372"}}},"outputs":[],"source":["def make_idx(file_name):\n","  train_data = pd.read_csv(file_name)\n","\n","  # 音樂會編流水號\n","  events = train_data['itemID'].drop_duplicates().sort_values().to_frame()\n","  events['item_idx'] = range(0, len(events))\n","  event_id_idx = events.set_index('itemID').T.to_dict('list')\n","\n","  # 使用者編流水號\n","  users = train_data['userID'].drop_duplicates().sort_values().to_frame()\n","  users['user_idx'] = range(0, len(users))\n","  user_id_idx = users.set_index('userID').T.to_dict('list')\n","\n","  #合併到 train 中\n","  train_data['user_idx'] = train_data['userID'].apply(lambda x : user_id_idx[x][0])\n","  train_data['item_idx'] = train_data['itemID'].apply(lambda x : event_id_idx[x][0])\n","\n","  # categorical col vocabularies\n","  feature_dict = {'userID' : train_data['userID'].unique(),\n","                  'itemID' : train_data['itemID'].unique(),\n","                  'dow' : train_data['dow'].unique(),\n","                  'inter' : train_data['inter'].unique(),\n","                  'category' : train_data['category'].unique(),\n","                  'recent_group' : train_data['recent_group'].unique(),\n","                  'order_concert_group' : train_data['order_concert_group'].unique()}\n","\n","  train_data.to_csv(file_name, index = False)\n","\n","  return user_id_idx, event_id_idx, feature_dict"]},{"cell_type":"markdown","metadata":{"id":"sl0m_AXOXZwf"},"source":["## tensorflow dataset"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"DTvHZJ-AXdDA","executionInfo":{"status":"ok","timestamp":1691382056271,"user_tz":-480,"elapsed":8,"user":{"displayName":"Ching-jung Lin","userId":"01061587562790755372"}}},"outputs":[],"source":["def data_interaction(train_path):\n","  train_set = pd.read_csv(train_path)\n","\n","  # interaction data\n","  # 使用者交易紀錄字典\n","  # 使用者如果對同一產品下單兩次，除非兩次下單時間與音樂會時間相隔日數可以落於不同組 (order_concert_group)，不然兩筆資料會只留一筆\n","  interactions_dict = train_set.groupby(['userID', 'user_idx', 'itemID', 'item_idx',\n","                                         'dow', 'inter', 'category', 'recent_group', 'order_concert_group'])['y'].sum().reset_index()\n","  del train_set\n","\n","  labels = interactions_dict['y']\n","  labels = tf.data.Dataset.from_tensor_slices(labels)\n","\n","  # 製作 interaction 用 title dataset\n","  train_title = interactions_dict['itemID'].to_frame()\n","\n","  train_title['title_idx'] = train_title['itemID'].apply(lambda x : title_enc_dict[x][0])\n","  train_title = train_title['title_idx']\n","  train_title = title_enc[train_title]\n","\n","  train_title = {'title_enc' : train_title}\n","  train_title = tf.data.Dataset.from_tensor_slices(train_title)\n","\n","  interactions_dict =  {name: np.array(value) for name, value in interactions_dict.items()} #{'userID':array(['userID', ...]), 'itemID':array(['itemID', ...])}    print('interactions_dict')\n","  interactions = tf.data.Dataset.from_tensor_slices(interactions_dict)\n","\n","  # 合併 interactions 和 train_title\n","  # 為 ZipDataset\n","  interactions = tf.data.Dataset.zip((interactions, train_title))\n","\n","  # map interactions and items to an identifier\n","  # key 是模型 input 層的名稱\n","  interactions = interactions.map(lambda x, y : {\n","      'userID' : x['userID'],\n","      'itemID' : x['itemID'],\n","      'users_in' : x['user_idx'],\n","      'recent_group_in' : x['recent_group'],\n","      'order_concert_group_in' : x['order_concert_group'],\n","      'items_in' : x['item_idx'],\n","      'dows_in' : x['dow'],\n","      'inter_in' : x['inter'],\n","      'cat_in' : x['category'],\n","      'title_in' : y['title_enc']\n","  })\n","\n","  interactions = tf.data.Dataset.zip((interactions, labels))\n","\n","  return interactions"]},{"cell_type":"markdown","metadata":{"id":"ekZZK0h4to9j"},"source":["# 模型架構"]},{"cell_type":"markdown","metadata":{"id":"NTC_11cweouB"},"source":["### create_model"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"axFUW9caaY-R","executionInfo":{"status":"ok","timestamp":1691382056271,"user_tz":-480,"elapsed":8,"user":{"displayName":"Ching-jung Lin","userId":"01061587562790755372"}}},"outputs":[],"source":["def create_model():\n","  users_in = layers.Input(name=\"users_in\", shape=(1,))\n","  items_in = layers.Input(name=\"items_in\", shape=(1,))\n","  dows_in = layers.Input(name='dows_in', shape=(1,), dtype=tf.string)\n","  inter_in = layers.Input(name='inter_in', shape=(1,), dtype=tf.string)\n","  cat_in = layers.Input(name='cat_in', shape=(1,), dtype=tf.string)\n","  recent_group_in = layers.Input(name='recent_group_in', shape=(1,))\n","  order_concert_group_in = layers.Input(name='order_concert_group_in', shape=(1,))\n","  title_in = layers.Input(name='title_in', shape=(512,))\n","\n","  user_embedding = int(len(feature_dict['userID'])/2)\n","  item_embedding = int(len(feature_dict['itemID'])/2)\n","  dow_embedding =  int(len(feature_dict['dow'])/2)\n","  inter_embedding = int(len(feature_dict['inter'])/2)\n","  cat_embedding = int(len(feature_dict['category'])/2)\n","  recent_embedding = int(len(feature_dict['recent_group'])/2)\n","  order_embedding = int(len(feature_dict['order_concert_group'])/2)\n","\n","  cf_emb = min(user_embedding, item_embedding)\n","\n","  drop_out = 0.2\n","  l2 = 0.02\n","\n","  ##  ===================== ##\n","  # feature embedding\n","\n","  users_emb = layers.Embedding(name='users_emb', input_dim=len(feature_dict['userID'])+1,\n","                               output_dim=user_embedding)(users_in)\n","  users_emb = layers.Reshape(target_shape=(user_embedding,))(users_emb)\n","\n","  items_emb = layers.Embedding(name='items_emb', input_dim=len(feature_dict['itemID'])+1,\n","                               output_dim=item_embedding)(items_in)\n","  items_emb = layers.Reshape(target_shape=(item_embedding, ))(items_emb)\n","\n","  # cf embedding\n","  users_emb_cf = layers.Embedding(name=\"users_emb_cf\", input_dim=len(feature_dict['userID'])+1,\n","                               output_dim=cf_emb)(users_in)\n","  users_emb_cf = layers.Reshape(target_shape = (cf_emb,))(users_emb_cf)\n","\n","  items_emb_cf = layers.Embedding(name=\"items_emb_cf\", input_dim=len(feature_dict['itemID'])+1,\n","                               output_dim=cf_emb)(items_in)\n","  items_emb_cf = layers.Reshape(target_shape = (cf_emb,))(items_emb_cf)\n","\n","  ## dow embedding\n","  dows_sl= layers.StringLookup(vocabulary=feature_dict['dow'], mask_token=None, name='dow_sl')\n","  dows_emb = dows_sl(dows_in)\n","  dows_emb = layers.Embedding(name='dows_emb', input_dim=len(feature_dict['dow'])+1,\n","                              output_dim=dow_embedding)(dows_emb)\n","  dows_emb = layers.Reshape(target_shape = (dow_embedding,))(dows_emb)\n","\n","  ## inter embedding\n","  inters_sl= layers.StringLookup(vocabulary=feature_dict['inter'], name='inters_sl')\n","  inters_emb = inters_sl(inter_in)\n","  inters_emb = layers.Embedding(name='inters_emb', input_dim=len(feature_dict['inter'])+1,\n","                                output_dim=inter_embedding)(inters_emb)\n","  inters_emb = layers.Reshape(target_shape = (inter_embedding,))(inters_emb)\n","\n","  ## category embedding\n","  cats_sl= layers.StringLookup(vocabulary=feature_dict['category'], name='cats_sl')\n","  cats_emb = cats_sl(cat_in)\n","  cats_emb = layers.Embedding(name='cats_emb', input_dim=len(feature_dict['category'])+1,\n","                              output_dim=cat_embedding)(cats_emb)\n","  cats_emb = layers.Reshape(target_shape = (cat_embedding,))(cats_emb)\n","\n","  ## recent group\n","  recent_il = layers.IntegerLookup(vocabulary=feature_dict['recent_group'])\n","  recent_emb = recent_il(recent_group_in)\n","  recent_emb = layers.Embedding(name='recent_emb', input_dim=len(feature_dict['recent_group'])+1,\n","                               output_dim=recent_embedding)(recent_emb)\n","  recent_emb = layers.Reshape(target_shape = (recent_embedding,))(recent_emb)\n","\n","  ## order_concert_group\n","  order_il = layers.IntegerLookup(vocabulary=feature_dict['order_concert_group'])\n","  order_emb = order_il(order_concert_group_in)\n","  order_emb = layers.Embedding(name='order_emb', input_dim=len(feature_dict['order_concert_group'])+1,\n","                               output_dim=order_embedding)(order_emb)\n","  order_emb = layers.Reshape(target_shape = (order_embedding,))(order_emb)\n","\n","  # title_enc\n","  title_emb = layers.Dense(512)(title_in)\n","\n","  ##  ===================== ##\n","  # cf\n","  # 使用者與物品內嵌向量內積\n","  cf_xx = tf.math.multiply(users_emb_cf, items_emb_cf)\n","\n","  ##  ===================== ##\n","  # nn\n","  feature_embs = tf.concat([users_emb, items_emb, order_emb,\n","                            cats_emb, dows_emb,\n","                            recent_emb, inters_emb,\n","                            title_emb], axis = 1)\n","\n","  nn_layer = layers.Dense(256, activation = 'relu',\n","                          kernel_regularizer=regularizers.L2(l2))(feature_embs)\n","  nn_layer = layers.Dropout(drop_out)(nn_layer)\n","  nn_layer = layers.Dense(128, activation='relu',\n","                          kernel_regularizer=regularizers.L2(l2))(nn_layer)\n","  nn_layer = layers.Dropout(drop_out)(nn_layer)\n","  nn_layer = layers.Dense(64, activation='relu',\n","                          kernel_regularizer=regularizers.L2(l2))(nn_layer)\n","  nn_layer = layers.Dense(16, activation='relu',\n","                          kernel_regularizer=regularizers.L2(l2))(nn_layer)\n","\n","  ##  ===================== ##\n","  # concat everything\n","  # cf 與 nn 輸出相接\n","  final_nn = tf.concat([cf_xx, nn_layer], axis = 1)\n","\n","  y_out = layers.Dense(units=2, activation = 'softmax', name='y_out')(final_nn)\n","  model = models.Model(inputs=[users_in, items_in,\n","                               dows_in,  inter_in, cat_in, recent_group_in,\n","                               order_concert_group_in, title_in],\n","                      outputs=y_out, name=\"Neural_CollaborativeFiltering\")\n","\n","  return model\n"]},{"cell_type":"markdown","metadata":{"id":"qcrpFtdb85WZ"},"source":["# 建立 / 讀入 df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IibdrN4V81mf"},"outputs":[],"source":["# 紀錄推薦清單長度為 10 與長度為 5 的結果\n","\n","file_name_10 = 'df_10.csv'\n","file_name_5 = 'df_5.csv'\n","\n","try:\n","  df_10 = pd.read_csv(file_name_10)\n","  print('read in df_10 file')\n","except:\n","  df_10 = pd.DataFrame(columns =  ['userID', 'rec_items', 'actual_event', 'actual_order', 'precision', 'recall', 'map', 'd'])\n","  df_10.to_csv(file_name_10, index = False)\n","  print('create df_10 file')\n","\n","try:\n","  df_5 = pd.read_csv(file_name_5)\n","  print('read in df_5 file')\n","except:\n","  df_5 = pd.DataFrame(columns =  ['userID', 'rec_items', 'actual_event', 'actual_order', 'precision', 'recall', 'map', 'd'])\n","  df_5.to_csv(file_name_5, index = False)\n","  print('create df_5 file')\n"]},{"cell_type":"markdown","metadata":{"id":"qrYQstETtR8s"},"source":["# 參數設定"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"mczvXOnDAW2x","executionInfo":{"status":"ok","timestamp":1691382056272,"user_tz":-480,"elapsed":7,"user":{"displayName":"Ching-jung Lin","userId":"01061587562790755372"}}},"outputs":[],"source":["# Model parameters\n","epochs = 50\n","batch_size = 100\n","lr = 0.0005\n","\n","rec_list_10 = 10\n","rec_list_5 = 5\n","\n","# callbacks\n","# val_loss 連續 5代都沒下降就結束訓練\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',\n","                                                  patience = 5,\n","                                                  restore_best_weights = True\n","                                                  )\n"]},{"cell_type":"markdown","metadata":{"id":"80tf9M4So1VE"},"source":["#main loop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vsBr8Q0tSEhK"},"outputs":[],"source":["# 23個訓練時間依序進行\n","for d in range(23):\n","  print('d=', d)\n","  train_time, train_path, avail_event, recent_group_dict = train_expand(d)\n","\n","  user_id_idx, item_id_idx, feature_dict = make_idx(train_path)\n","\n","  interactions = data_interaction(train_path)\n","\n","  # shuffle & split\n","  shuffled = interactions.shuffle(100_000, reshuffle_each_iteration=False)\n","  del interactions\n","\n","  # 用 dataset 無法在 fit 中使用 validation_split\n","  # 所以先分好：訓練集 0.9、餘下的為驗證集\n","  train_len = int(len(shuffled)*0.9)\n","  val_len = len(shuffled) - train_len\n","\n","  train = shuffled.take(train_len)\n","  val = shuffled.skip(train_len).take(val_len)\n","\n","  cached_train = train.batch(1000).cache()\n","  cached_val = val.batch(1000).cache()\n","\n","  # 儲存 logs\n","  log_file_name = '/content/drive/MyDrive/Colab Notebooks/final_model/train_' + str(d) + '.log'\n","  csv_logger = tf.keras.callbacks.CSVLogger(log_file_name)\n","\n","  model = create_model()\n","\n","  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n","                loss= tf.keras.losses.SparseCategoricalCrossentropy(),\n","                metrics= tf.keras.metrics.SparseCategoricalAccuracy())\n","\n","  model.fit(cached_train, validation_data = cached_val, shuffle=True,\n","            epochs=epochs, batch_size=batch_size,\n","            callbacks=[early_stopping, csv_logger])\n","\n","  del shuffled, train, val, cached_train, cached_val\n","  gc.collect()\n","\n","  ### =============== ###\n","  # 預測\n","  # 只用訓練集中的使用者，且使用者買過訓練集中已上架節目的資料做為測試\n","  s_time = time.time()\n","  raw_data = pd.read_csv(raw_data_file_name)\n","\n","  #把日期相關欄位轉為日期格式 yyyy-mm-dd hh:mm:ss\n","  raw_data['order_time'] = pd.DatetimeIndex(raw_data['訂單日期'])\n","  raw_data['first_order'] = pd.DatetimeIndex(raw_data['first_order'])\n","  raw_data['concert_time'] = pd.DatetimeIndex(raw_data['concert_time'])\n","  raw_data['title'] = raw_data['產品名稱']\n","\n","  test = raw_data[raw_data['order_time'] >= train_time]\n","  test = test[(test['userID'].isin(feature_dict['userID'])) & (test['itemID'].isin(avail_event))]\n","  del raw_data\n","  gc.collect()\n","\n","  test['user_idx'] = test['userID'].apply(lambda x : user_id_idx[x][0])\n","  test['item_idx'] = test['itemID'].apply(lambda x : item_id_idx[x][0])\n","\n","  # user_idx 清單\n","  test_user = list(test['user_idx'].unique())\n","\n","  for i in range(len(test_user)):\n","    df_10 = pd.DataFrame(columns =  ['userID', 'rec_items', 'actual_event', 'actual_order', 'precision', 'recall', 'map', 'd'])\n","    df_5 = pd.DataFrame(columns =  ['userID', 'rec_items', 'actual_event', 'actual_order', 'precision', 'recall', 'map', 'd'])\n","    dic_10 = {}\n","    dic_5 = {}\n","\n","    # 製作測試資料：候選節目為 avail_event\n","    # 需要重建 item 資料\n","    rec_items = pd.DataFrame(avail_event, columns = ['itemID'])\n","    rec_items['item_idx'] = rec_items['itemID'].apply(lambda x : item_id_idx[x][0])\n","    rec_items = rec_items.merge(title[['title', 'itemID']], how = 'left', on = ['itemID'])\n","    rec_items['concert_time'] = rec_items['itemID'].apply(lambda x : concert_time_dict[x]['concert_time'])\n","    rec_items['dow'] = rec_items['itemID'].apply(lambda x : dow_dict[x][0])\n","    rec_items['inter'] = rec_items['itemID'].apply(lambda x : inter_dict[x][0])\n","    rec_items['category'] = rec_items['itemID'].apply(lambda x : cat_dict[x][0])\n","\n","    user = test_user[i]\n","    rec_items['user_idx'] = user\n","    userID = list(user_id_idx.keys())[list(user_id_idx.values()).index([user])]\n","    rec_items['userID'] = userID\n","    rec_items['recent_group'] = rec_items['userID'].apply(lambda x : recent_group_dict[x][0])\n","\n","    # 計算 order_concert 分組\n","    rec_items['order_concert'] = rec_items['concert_time'] - train_time\n","    rec_items['order_concert'] = rec_items['order_concert'].dt.days\n","    rec_items['order_concert_group'] = rec_items['order_concert'].apply(lambda x : 0 if x == 0 else\n","                                                                        1 if x <= 7 else\n","                                                                        2 if x <= 14 else\n","                                                                        3 if x <= 30 else\n","                                                                        4 if x <= 60 else 5)\n","\n","    # 找出 test_enc\n","    test_title_idx = rec_items.merge(title, on = 'itemID', how = 'left')['title_idx']\n","    test_enc = title_enc[test_title_idx]\n","\n","    # 預測\n","    preds = model.predict([rec_items['user_idx'], rec_items['item_idx'], rec_items['dow'],\n","                          rec_items['inter'], rec_items['category'], rec_items['recent_group'],\n","                          rec_items['order_concert_group'],\n","                          test_enc], verbose = 0)\n","\n","    # 將預測分數併到 rec_items 中\n","    preds = pd.DataFrame(preds, columns = ['pred_0', 'pred_1'])\n","    rec_items = rec_items.reset_index(drop = True)\n","    rec_items = rec_items.merge(preds['pred_1'].rename('pred'), left_index = True, right_index = True)\n","    rec_items = rec_items.sort_values(by = 'pred', ascending = False).reset_index(drop = True)\n","\n","    # 使用者實際購買\n","    actual_event = test[test['user_idx'] == user].drop_duplicates(subset='itemID')\n","    actual_event_id = list(actual_event['itemID'])\n","    actual_event_name = list(set(actual_event['title']))\n","\n","    # 直接用產品名稱找 hit\n","    # 刪除產品名相同的列\n","    rec_items = rec_items.drop_duplicates(subset = 'title').reset_index(drop = True)\n","    rec_items['hit'] = rec_items['title'].apply(lambda x : 1 if x in actual_event_name else 0)\n","\n","    actual_order = list(rec_items[rec_items['title'].isin(actual_event_name)].index+1)\n","\n","    # top k\n","    rec_items_10 = rec_items[:rec_list_10]\n","    rec_items_5 = rec_items[:rec_list_5]\n","    print(rec_items_10)\n","\n","    precision_10 = rec_items_10['hit'].sum() / rec_list_10\n","    precision_5 = rec_items_5['hit'].sum() / rec_list_5\n","    recall_10 = rec_items_10['hit'].sum() / len(set(actual_event_name)) #同名只會有一個 hit\n","    recall_5 = rec_items_5['hit'].sum() / len(set(actual_event_name))\n","\n","    # 計算 average precision\n","    rec_items_10['rank'] =[r for r in range(1, rec_list_10+1)]\n","    rec_items_10['cumsum'] = rec_items_10['hit'].cumsum()\n","    rec_items_10['rr'] = rec_items_10['cumsum']/rec_items_10['rank']\n","    map_10 = (rec_items_10['rr']*rec_items_10['hit']).sum()/len(set(actual_event_name))\n","\n","    rec_items_5['rank'] =[r for r in range(1, rec_list_5+1)]\n","    rec_items_5['cumsum'] = rec_items_5['hit'].cumsum()\n","    rec_items_5['rr'] = rec_items_5['cumsum']/rec_items_5['rank']\n","    map_5 = (rec_items_5['rr']*rec_items_5['hit']).sum()/len(set(actual_event_name))\n","\n","    dic_10 = {'userID' : rec_items_10['userID'].unique(), 'rec_items' : list(rec_items_10['itemID']),\n","              'actual_event' : actual_event_id, 'actual_order' : actual_order,\n","              'precision' : precision_10, 'recall' : recall_10, 'map' : map_10, 'd' : d}\n","    df_10 = df_10.append(dic_10, ignore_index = True)\n","    df_10.to_csv(file_name_10, mode = 'a', index = False, header = False)\n","\n","    dic_5 = {'userID' : rec_items_5['userID'].unique(), 'rec_items' : list(rec_items_5['itemID']),\n","              'actual_event' : actual_event_id, 'actual_order' : actual_order,\n","              'precision' : precision_5, 'recall' : recall_5, 'map' : map_5, 'd' : d}\n","    df_5 = df_5.append(dic_5, ignore_index = True)\n","    df_5.to_csv(file_name_5, mode = 'a', index = False, header = False)\n","\n","  del actual_event, actual_event_id, actual_event_name, actual_order, avail_event\n","  del df_10, df_5, dic_10, dic_5, item_id_idx, user_id_idx\n","  del recent_group_dict\n","  del test, test_user\n","  del rec_items, preds\n","\n","  gc.collect()\n","\n","  del model\n","  gc.collect()\n","\n","  #from numba import cuda\n","  from keras import backend as K\n","\n","  K.clear_session()\n","  gc.collect()\n","\n","df_10 = pd.read_csv(file_name_10)\n","print('n = 10')\n","print('mean precision', df_10['precision'].mean())\n","print('mean recall', df_10['recall'].mean())\n","print('mean average precision', df_10['map'].mean())\n","print()\n","\n","df_5 = pd.read_csv(file_name_5)\n","print('n = 5')\n","print('mean precision', df_5['precision'].mean())\n","print('mean recall', df_5['recall'].mean())\n","print('mean average precision', df_5['map'].mean())\n"]},{"cell_type":"markdown","metadata":{"id":"Jb0eWYvpupD-"},"source":["# end session"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A4zTMBW5VJky","executionInfo":{"status":"aborted","timestamp":1691382107571,"user_tz":-480,"elapsed":5,"user":{"displayName":"Ching-jung Lin","userId":"01061587562790755372"}}},"outputs":[],"source":["from google.colab import runtime\n","runtime.unassign()"]}],"metadata":{"colab":{"provenance":[{"file_id":"18XMzEDIossbKhKXb85NPfwJTO0ee8WIQ","timestamp":1691379597291},{"file_id":"10GV91TCwl_FDA37IOZL9Odt3CgVDnmC3","timestamp":1677665879512},{"file_id":"1wkVRNt67_VROIyTleuwL09knS0cfLyzt","timestamp":1677386425304},{"file_id":"1y0u8PDs9rF33ic19kztkJh7eTFTqhwGv","timestamp":1675778482310},{"file_id":"1qXmdoa9X6kxFBlceDFIVV_2hfHg5a354","timestamp":1675654434562}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}
